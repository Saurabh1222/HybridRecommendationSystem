{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg/Q3SXsY8hAuCvZUX6ska",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saurabh1222/HybridRecommendationSystem/blob/main/HybridRecommendationSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Core Model: Hybrid Filtering\n",
        "The primary goal is to combine the strengths of two fundamental recommendation approaches:\n",
        "\n",
        "### Content-Based Filtering (CBF): Recommends items similar to what the user has liked in the past.\n",
        "\n",
        "- Data Used: Restaurant/Dish features (cuisine, cost, ingredients, veg/non-veg, restaurant tags, menu descriptions).\n",
        "\n",
        "- Goal: Recommending a new North Indian restaurant to a user who frequently orders from different North Indian places.\n",
        "\n",
        "### Collaborative Filtering (CF): Recommends items that similar users have liked.\n",
        "\n",
        "- Data Used: User-Item interaction data (ratings, past orders, clicks, searches).\n",
        "\n",
        "- Goal: Recommending a Biryani to a user whose peer group (users with similar ordering history) frequently orders that specific Biryani."
      ],
      "metadata": {
        "id": "K95D9dnEBt2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection & Preprocessing:\n",
        "\n",
        "- Acquire or simulate a dataset containing User IDs, Restaurant IDs, Dish IDs, Ratings/Reviews, Order History, Cuisine Type, Cost, and Timestamps.\n",
        "\n",
        "- Clean and transform raw data into a suitable format (e.g., a sparse User-Item interaction matrix)."
      ],
      "metadata": {
        "id": "Ds-EKl7kKZtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USSbUwg-8U5Q",
        "outputId": "8cc58bb9-1d56-484e-d3d7-1b0673d2aa51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Orders Data Head ---\n",
            "   user_id  item_id  rating  timestamp\n",
            "0       52       12       2 2024-01-29\n",
            "1       93       26       1 2024-11-13\n",
            "2       15       16       4 2024-09-01\n",
            "3       72       37       3 2024-08-23\n",
            "4       61       22       2 2024-07-03\n",
            "\n",
            "--- Features Data Head ---\n",
            "   item_id    cuisine                                   tags  avg_price\n",
            "0        1    Chinese  premium, vegetarian, delivery-focused      699.0\n",
            "1        2     Indian                             vegetarian      602.0\n",
            "2        3  Fast Food    vegetarian, delivery-focused, spicy      242.0\n",
            "3        4    Mexican                spicy, delivery-focused      584.0\n",
            "4        5    Chinese           vegetarian, delivery-focused      363.0\n"
          ]
        }
      ],
      "source": [
        "#%%writefile data_generator.py\n",
        "# Data Generator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def generate_synthetic_data(num_users=100, num_restaurants=50, max_orders=500):\n",
        "    \"\"\"\n",
        "    Generates synthetic data for User Orders and Restaurant Features.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # 1. User-Item Interaction Data (Orders/Ratings)\n",
        "    user_ids = np.random.randint(1, num_users + 1, max_orders)\n",
        "    restaurant_ids = np.random.randint(1, num_restaurants + 1, max_orders)\n",
        "    ratings = np.random.randint(1, 6, max_orders) # 1 to 5 star rating\n",
        "    timestamps = pd.to_datetime('2024-01-01') + pd.to_timedelta(np.random.randint(0, 365, max_orders), unit='D')\n",
        "\n",
        "    orders_df = pd.DataFrame({\n",
        "        'user_id': user_ids,\n",
        "        'item_id': restaurant_ids,\n",
        "        'rating': ratings,\n",
        "        'timestamp': timestamps\n",
        "    })\n",
        "\n",
        "    # 2. Restaurant Feature Data (for Content-Based Filtering)\n",
        "    cuisines = ['Indian', 'Chinese', 'Italian', 'Mexican', 'Fast Food']\n",
        "    features = ['spicy', 'vegetarian', 'delivery-focused', 'budget', 'premium']\n",
        "\n",
        "    features_data = {\n",
        "        'item_id': np.arange(1, num_restaurants + 1),\n",
        "        'cuisine': np.random.choice(cuisines, num_restaurants),\n",
        "        'tags': [', '.join(np.random.choice(features, np.random.randint(1, 4), replace=False)) for _ in range(num_restaurants)],\n",
        "        'avg_price': np.round(np.random.uniform(200, 800, num_restaurants), 0)\n",
        "    }\n",
        "    features_df = pd.DataFrame(features_data)\n",
        "\n",
        "    return orders_df, features_df\n",
        "\n",
        "\n",
        "orders, features = generate_synthetic_data()\n",
        "print(\"--- Orders Data Head ---\")\n",
        "print(orders.head())\n",
        "print(\"\\n--- Features Data Head ---\")\n",
        "print(features.head())\n",
        "# Save the data for use in other modules\n",
        "orders.to_csv('orders.csv', index=False)\n",
        "features.to_csv('features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content Based Filtering\n",
        "### Generating recommendations based on restaurant features using TF-IDF and Cosine Similarity."
      ],
      "metadata": {
        "id": "uWqL4DAsDZpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile content_filter.py\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class ContentBasedRecommender:\n",
        "    def __init__(self, features_df):\n",
        "        \"\"\"\n",
        "        Initializes the Content-Based Recommender.\n",
        "        \"\"\"\n",
        "        self.features_df = features_df.set_index('item_id')\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        self.cosine_sim = None\n",
        "        self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"\n",
        "        Processes features (cuisine + tags) and computes the Cosine Similarity matrix.\n",
        "        \"\"\"\n",
        "        # Combine relevant text features into one string\n",
        "        self.features_df['combined_features'] = (\n",
        "            self.features_df['cuisine'].str.strip() + ' ' + self.features_df['tags'].str.strip()\n",
        "        )\n",
        "\n",
        "        # Create the TF-IDF matrix\n",
        "        tfidf_matrix = self.vectorizer.fit_transform(self.features_df['combined_features'])\n",
        "\n",
        "        # Compute the cosine similarity matrix\n",
        "        self.cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    def get_recommendations(self, item_id, top_n=10):\n",
        "        \"\"\"\n",
        "        Recommends items similar to the given item_id.\n",
        "        Returns a list of (item_id, similarity_score) tuples.\n",
        "        \"\"\"\n",
        "        if item_id not in self.features_df.index:\n",
        "            return []\n",
        "\n",
        "        # Get the index of the item that matches the item_id\n",
        "        idx = self.features_df.index.get_loc(item_id)\n",
        "\n",
        "        # Get the pairwise similarity scores\n",
        "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
        "\n",
        "        # Sort the restaurants based on the similarity scores\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get the scores of the top_n most similar items (excluding itself)\n",
        "        sim_scores = sim_scores[1:top_n+1]\n",
        "\n",
        "        # Get the item indices and scores\n",
        "        item_indices = [i[0] for i in sim_scores]\n",
        "        scores = [i[1] for i in sim_scores]\n",
        "\n",
        "        # Map back to item_id\n",
        "        recommended_items = self.features_df.iloc[item_indices].index.tolist()\n",
        "\n",
        "        return list(zip(recommended_items, scores))\n",
        "\n",
        "\n",
        "# Load data generated in the previous step\n",
        "features_df = pd.read_csv('features.csv')\n",
        "\n",
        "cbf_recommender = ContentBasedRecommender(features_df)\n",
        "\n",
        "# Get recommendations for item_id 1\n",
        "item_id_to_test = 1\n",
        "recommendations = cbf_recommender.get_recommendations(item_id_to_test)\n",
        "\n",
        "print(f\"\\n--- Content-Based Recommendations for Item {item_id_to_test} ---\")\n",
        "print(f\"Top 5 Recommendations: {recommendations[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "088Z9XGZDUqU",
        "outputId": "11219b14-8bf2-4ad3-d513-17a42b7a8a1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Content-Based Recommendations for Item 1 ---\n",
            "Top 5 Recommendations: [(5, 0.895913640502298), (29, 0.8042668552056544), (37, 0.7986381544578232), (17, 0.7840524295710705), (34, 0.7840524295710705)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative based filtering\n",
        "Use the Surprise library to implement a collaborative filtering model (SVD)."
      ],
      "metadata": {
        "id": "B6es_mTHF6u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "m7MpbCgzHCk0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "id": "vMWUG0rCHRSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile collaborative_filter.py\n",
        "import pandas as pd\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "class CollaborativeRecommender:\n",
        "    def __init__(self, orders_df):\n",
        "        \"\"\"\n",
        "        Initializes and trains the Collaborative Filtering model (SVD).\n",
        "        \"\"\"\n",
        "        self.orders_df = orders_df\n",
        "        # Surprise requires data in a specific format (User, Item, Rating)\n",
        "        self.reader = Reader(rating_scale=(1, 5))\n",
        "        self.data = Dataset.load_from_df(\n",
        "            self.orders_df[['user_id', 'item_id', 'rating']],\n",
        "            self.reader\n",
        "        )\n",
        "        self.trainset = self.data.build_full_trainset()\n",
        "        self.model = SVD(n_epochs=20, n_factors=50, random_state=42)\n",
        "        self._train_model()\n",
        "\n",
        "    def _train_model(self):\n",
        "        \"\"\"\n",
        "        Trains the SVD model on the full dataset.\n",
        "        \"\"\"\n",
        "        self.model.fit(self.trainset)\n",
        "\n",
        "        # Optional: Evaluate the model on a test set (not strictly needed for production prediction)\n",
        "        # trainset, testset = train_test_split(self.data, test_size=0.2, random_state=42)\n",
        "        # self.model.fit(trainset)\n",
        "        # predictions = self.model.test(testset)\n",
        "        # print(f\"CF Model RMSE: {accuracy.rmse(predictions, verbose=False)}\")\n",
        "\n",
        "\n",
        "    def predict_score(self, user_id, item_id):\n",
        "        \"\"\"\n",
        "        Predicts the rating a user would give to an item.\n",
        "        \"\"\"\n",
        "        # The estimate (est) is the predicted rating.\n",
        "        prediction = self.model.predict(user_id, item_id)\n",
        "        return prediction.est\n",
        "\n",
        "    def get_top_n_recommendations(self, user_id, all_item_ids, top_n=10):\n",
        "        \"\"\"\n",
        "        Generates top N item recommendations for a given user.\n",
        "        \"\"\"\n",
        "        # Get items the user hasn't rated/ordered yet\n",
        "        user_ordered_items = self.orders_df[self.orders_df['user_id'] == user_id]['item_id'].unique()\n",
        "        items_to_predict = [item for item in all_item_ids if item not in user_ordered_items]\n",
        "\n",
        "        # Predict ratings for all potential items\n",
        "        predictions = []\n",
        "        for item_id in items_to_predict:\n",
        "            score = self.predict_score(user_id, item_id)\n",
        "            predictions.append((item_id, score))\n",
        "\n",
        "        # Sort by predicted score\n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return predictions[:top_n]\n",
        "\n",
        "\n",
        "# Load data\n",
        "orders_df = pd.read_csv('orders.csv')\n",
        "all_item_ids = orders_df['item_id'].unique().tolist()\n",
        "\n",
        "cf_recommender = CollaborativeRecommender(orders_df)\n",
        "\n",
        "# Get recommendations for user 10\n",
        "user_id_to_test = 10\n",
        "recommendations = cf_recommender.get_top_n_recommendations(user_id_to_test, all_item_ids)\n",
        "\n",
        "print(f\"\\n--- Collaborative Filtering Recommendations for User {user_id_to_test} ---\")\n",
        "print(f\"Top 5 Recommendations: {recommendations[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK5LA3sPFz4T",
        "outputId": "c56e67da-8bb3-4ed8-d80f-cd5d8f7ac2e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Collaborative Filtering Recommendations for User 10 ---\n",
            "Top 5 Recommendations: [(35, 3.684305626538732), (42, 3.367812693564362), (39, 3.361375030569888), (4, 3.315204626329262), (30, 3.2882940994001255)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Recommendation\n",
        "This is the main module that integrates the two models and applies contextual filtering."
      ],
      "metadata": {
        "id": "Zs0zIPo1IQnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Develop boosting/penalizing logic to adjust the final recommendation score based on real-time factors."
      ],
      "metadata": {
        "id": "3awlTRuuKw1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from content_filter import ContentBasedRecommender\n",
        "from collaborative_filter import CollaborativeRecommender\n",
        "from datetime import datetime\n",
        "\n",
        "class HybridRecommender:\n",
        "    def __init__(self, orders_df, features_df):\n",
        "        \"\"\"\n",
        "        Initializes the Hybrid Recommender with both models.\n",
        "        \"\"\"\n",
        "        self.cbf = ContentBasedRecommender(features_df)\n",
        "        self.cf = CollaborativeRecommender(orders_df)\n",
        "        self.all_item_ids = orders_df['item_id'].unique().tolist()\n",
        "\n",
        "        # Hyperparameter for blending the two scores\n",
        "        self.cf_weight = 0.6  # 60% Collaborative, 40% Content-Based\n",
        "        self.cbf_weight = 1.0 - self.cf_weight\n",
        "\n",
        "    def _get_time_factor(self, current_time):\n",
        "        \"\"\"\n",
        "        Simple contextual logic: Boost certain cuisines based on time of day.\n",
        "        Returns a dictionary of {item_id: score_multiplier}.\n",
        "        \"\"\"\n",
        "        hour = current_time.hour\n",
        "\n",
        "        # Example logic: Boost 'Indian' cuisine for Lunch (12-2 PM)\n",
        "        time_boost_factor = 1.15 if 12 <= hour < 14 else 1.0\n",
        "\n",
        "\n",
        "        time_boosts = {}\n",
        "        for item_id in self.all_item_ids:\n",
        "            # Placeholder for actual cuisine lookup\n",
        "            is_indian = item_id <= 10 # Example: Items 1-10 are 'Indian'\n",
        "            time_boosts[item_id] = time_boost_factor if is_indian else 1.0\n",
        "\n",
        "        return time_boosts\n",
        "\n",
        "    def recommend(self, user_id, last_ordered_item, top_n=10, current_time=None):\n",
        "        \"\"\"\n",
        "        Generates hybrid and contextually filtered recommendations.\n",
        "        \"\"\"\n",
        "        if current_time is None:\n",
        "            current_time = datetime.now()\n",
        "\n",
        "        # 1. Get CF scores (predicted ratings)\n",
        "        cf_predictions = self.cf.get_top_n_recommendations(user_id, self.all_item_ids, top_n=len(self.all_item_ids))\n",
        "        cf_scores = {item: score for item, score in cf_predictions}\n",
        "\n",
        "        # 2. Get CBF scores (similarity to last ordered item)\n",
        "        cbf_scores_list = self.cbf.get_recommendations(last_ordered_item, top_n=len(self.all_item_ids))\n",
        "        cbf_scores = {item: score for item, score in cbf_scores_list}\n",
        "\n",
        "        # 3. Apply Time-based Contextual Filtering\n",
        "        time_factors = self._get_time_factor(current_time)\n",
        "\n",
        "        final_recommendations = {}\n",
        "        for item_id in self.all_item_ids:\n",
        "            # Check if item has a CF score (it always should, but good practice)\n",
        "            if item_id in cf_scores:\n",
        "                # Get the scores, using 0 if CBF score is missing (i.e., item is not similar to last order)\n",
        "                cf_score = cf_scores.get(item_id, 0) / 5.0 # Normalize CF rating (1-5) to (0-1)\n",
        "                cbf_score = cbf_scores.get(item_id, 0)     # CBF score is already (0-1)\n",
        "\n",
        "                # **Hybrid Blending Formula**\n",
        "                hybrid_score = (self.cf_weight * cf_score) + (self.cbf_weight * cbf_score)\n",
        "\n",
        "                # **Contextual Adjustment**\n",
        "                contextual_factor = time_factors.get(item_id, 1.0)\n",
        "                final_score = hybrid_score * contextual_factor\n",
        "\n",
        "                final_recommendations[item_id] = final_score\n",
        "\n",
        "        # Sort and return top N\n",
        "        sorted_recommendations = sorted(final_recommendations.items(), key=lambda item: item[1], reverse=True)\n",
        "        return sorted_recommendations[:top_n]\n",
        "\n",
        "\n",
        "# Load data\n",
        "orders_df = pd.read_csv('orders.csv')\n",
        "features_df = pd.read_csv('features.csv')\n",
        "\n",
        "# Initialize the system\n",
        "hybrid_system = HybridRecommender(orders_df, features_df)\n",
        "\n",
        "# Test case: Recommend for User 10, whose last order was Item 5\n",
        "user_id_test = 10\n",
        "last_item_test = 5\n",
        "\n",
        "print(f\"\\n--- Hybrid & Contextual Recommendations for User {user_id_test} ---\")\n",
        "\n",
        "# Simulate a Lunchtime request (1 PM)\n",
        "lunch_time = datetime(2025, 1, 1, 13, 0, 0)\n",
        "recs_lunch = hybrid_system.recommend(user_id_test, last_item_test, top_n=5, current_time=lunch_time)\n",
        "print(f\"\\n[Lunchtime (1 PM) - Boosts Indian (ID <= 10)]\")\n",
        "for item_id, score in recs_lunch:\n",
        "    print(f\"Item ID: {item_id}, Score: {score:.4f}\")\n",
        "\n",
        "# Simulate an Off-peak request (4 PM)\n",
        "off_peak_time = datetime(2025, 1, 1, 16, 0, 0)\n",
        "recs_offpeak = hybrid_system.recommend(user_id_test, last_item_test, top_n=5, current_time=off_peak_time)\n",
        "print(f\"\\n[Off-Peak (4 PM) - No Special Boost]\")\n",
        "for item_id, score in recs_offpeak:\n",
        "    print(f\"Item ID: {item_id}, Score: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJvHYixUIVmQ",
        "outputId": "560abc6d-ce7f-44aa-e93b-fbf6dbba7224"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hybrid & Contextual Recommendations for User 10 ---\n",
            "4\n",
            "[(0, 0.895913640502298), (1, 0.27295905888710303), (2, 0.5060907449541091), (3, 0.3921942934369847), (4, 1.0), (5, 0.22292831253440754), (6, 0.0), (7, 0.0), (8, 0.3572280245027837), (9, 0.17958194072706923), (10, 0.21712434685588702), (11, 0.19501933924673487), (12, 0.27295905888710303), (13, 0.0), (14, 0.3921942934369847), (15, 0.34922795063564316), (16, 0.8751428643630069), (17, 0.0), (18, 0.18467307799353183), (19, 0.35205983720306755), (20, 0.2578491522534077), (21, 0.5502524723326633), (22, 0.5162165119877451), (23, 0.0), (24, 0.42497077280470674), (25, 0.18467307799353183), (26, 0.3935503809390608), (27, 0.0), (28, 0.6795588029593385), (29, 0.35058100095065503), (30, 0.6036175177585501), (31, 0.18025041208378145), (32, 0.3806369112215798), (33, 0.8751428643630069), (34, 0.8751428643630069), (35, 0.5502524723326633), (36, 0.8914231443223288), (37, 0.0), (38, 0.36059254731655405), (39, 0.33088629770720684), (40, 0.0), (41, 0.5382926662599099), (42, 0.45842666966706647), (43, 0.42497077280470674), (44, 0.0), (45, 0.7440935833577258), (46, 0.35205983720306755), (47, 0.7288581707822857), (48, 0.5694429359047547), (49, 0.5862512208200233)]\n",
            "[1, 37, 17, 34, 35, 46, 48, 29, 31, 50, 49, 22, 36, 42, 23, 3, 43, 25, 44, 27, 4, 15, 33, 39, 9, 20, 47, 30, 16, 40, 2, 13, 21, 6, 11, 12, 19, 26, 32, 10, 7, 8, 14, 18, 24, 28, 38, 41, 45]\n",
            "\n",
            "[Lunchtime (1 PM) - Boosts Indian (ID <= 10)]\n",
            "Item ID: 35, Score: 0.7922\n",
            "Item ID: 1, Score: 0.7645\n",
            "Item ID: 37, Score: 0.7349\n",
            "Item ID: 34, Score: 0.7066\n",
            "Item ID: 17, Score: 0.6963\n",
            "4\n",
            "[(0, 0.895913640502298), (1, 0.27295905888710303), (2, 0.5060907449541091), (3, 0.3921942934369847), (4, 1.0), (5, 0.22292831253440754), (6, 0.0), (7, 0.0), (8, 0.3572280245027837), (9, 0.17958194072706923), (10, 0.21712434685588702), (11, 0.19501933924673487), (12, 0.27295905888710303), (13, 0.0), (14, 0.3921942934369847), (15, 0.34922795063564316), (16, 0.8751428643630069), (17, 0.0), (18, 0.18467307799353183), (19, 0.35205983720306755), (20, 0.2578491522534077), (21, 0.5502524723326633), (22, 0.5162165119877451), (23, 0.0), (24, 0.42497077280470674), (25, 0.18467307799353183), (26, 0.3935503809390608), (27, 0.0), (28, 0.6795588029593385), (29, 0.35058100095065503), (30, 0.6036175177585501), (31, 0.18025041208378145), (32, 0.3806369112215798), (33, 0.8751428643630069), (34, 0.8751428643630069), (35, 0.5502524723326633), (36, 0.8914231443223288), (37, 0.0), (38, 0.36059254731655405), (39, 0.33088629770720684), (40, 0.0), (41, 0.5382926662599099), (42, 0.45842666966706647), (43, 0.42497077280470674), (44, 0.0), (45, 0.7440935833577258), (46, 0.35205983720306755), (47, 0.7288581707822857), (48, 0.5694429359047547), (49, 0.5862512208200233)]\n",
            "[1, 37, 17, 34, 35, 46, 48, 29, 31, 50, 49, 22, 36, 42, 23, 3, 43, 25, 44, 27, 4, 15, 33, 39, 9, 20, 47, 30, 16, 40, 2, 13, 21, 6, 11, 12, 19, 26, 32, 10, 7, 8, 14, 18, 24, 28, 38, 41, 45]\n",
            "\n",
            "[Off-Peak (4 PM) - No Special Boost]\n",
            "Item ID: 35, Score: 0.7922\n",
            "Item ID: 37, Score: 0.7349\n",
            "Item ID: 34, Score: 0.7066\n",
            "Item ID: 17, Score: 0.6963\n",
            "Item ID: 46, Score: 0.6659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation:\n",
        "\n",
        "Evaluated the model using metrics like Precision@k, Recall@k, and Root Mean Square Error (RMSE).\n",
        "\n",
        "A critical real-world metric would be Click-Through Rate (CTR) or Conversion Rate (Orders placed) for the recommended items."
      ],
      "metadata": {
        "id": "R8WwcgpbLeHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split, KFold\n",
        "from collections import defaultdict # Used for Top-N metrics\n",
        "\n",
        "# Helper function for calculating Precision and Recall (Standard Surprise pattern)\n",
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"Return the top N recommendation for each user from a set of predictions.\"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    \"\"\"\n",
        "    Return precision and recall at k, calculated using a relevance threshold.\n",
        "    A rating is considered 'relevant' if it is above the threshold.\n",
        "    \"\"\"\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= 0) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= 0))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@k: Proportion of recommended items that are relevant\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        # Recall@k: Proportion of relevant items that are recommended\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls\n",
        "\n",
        "\n",
        "class RecommenderEvaluator:\n",
        "    def __init__(self, orders_df):\n",
        "        self.orders_df = orders_df\n",
        "        self.reader = Reader(rating_scale=(1, 5))\n",
        "        self.data = Dataset.load_from_df(\n",
        "            self.orders_df[['user_id', 'item_id', 'rating']],\n",
        "            self.reader\n",
        "        )\n",
        "        self.all_item_ids = self.orders_df['item_id'].unique().tolist()\n",
        "\n",
        "    def evaluate_collaborative_filter(self, model_class=SVD, test_size=0.2):\n",
        "        \"\"\"\n",
        "        Trains and evaluates a Collaborative Filtering model using RMSE/MAE.\n",
        "        \"\"\"\n",
        "        print(f\"--- Evaluating Collaborative Filtering Model ({model_class.__name__}) ---\")\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        trainset, testset = train_test_split(self.data, test_size=test_size, random_state=42)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = model_class(random_state=42)\n",
        "        model.fit(trainset)\n",
        "\n",
        "        # Predict ratings on the test set\n",
        "        predictions = model.test(testset)\n",
        "\n",
        "        # Compute metrics\n",
        "        rmse = accuracy.rmse(predictions, verbose=False)\n",
        "        mae = accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "        print(f\"  Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
        "        print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "\n",
        "        return {'RMSE': rmse, 'MAE': mae}\n",
        "\n",
        "    def evaluate_top_n(self, model_class=SVD, k=5, threshold=3.5):\n",
        "        \"\"\"\n",
        "        Performs robust Top-N evaluation using K-Fold cross-validation\n",
        "        and the helper function pattern for Precision and Recall.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Evaluating Top-{k} Recommendation Quality (Precision/Recall) ---\")\n",
        "        print(f\"Using relevance threshold: {threshold} (e.g., ratings >= 4 are 'relevant')\")\n",
        "\n",
        "        kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
        "        model = model_class(random_state=42)\n",
        "\n",
        "        all_precisions = []\n",
        "        all_recalls = []\n",
        "\n",
        "        for trainset, testset in kf.split(self.data):\n",
        "            # Train model\n",
        "            model.fit(trainset)\n",
        "\n",
        "            # Get predictions on the test set\n",
        "            predictions = model.test(testset)\n",
        "\n",
        "            # Calculate Precision and Recall for this fold\n",
        "            precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=threshold)\n",
        "\n",
        "            # Store average precision and recall for this fold\n",
        "            all_precisions.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
        "            all_recalls.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
        "\n",
        "        # Aggregate results\n",
        "        avg_precision = np.mean(all_precisions)\n",
        "        avg_recall = np.mean(all_recalls)\n",
        "\n",
        "        # F1 Score is the harmonic mean\n",
        "        f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
        "\n",
        "        print(f\"  Average Precision@{k}: {avg_precision:.4f}\")\n",
        "        print(f\"  Average Recall@{k}: {avg_recall:.4f}\")\n",
        "        print(f\"  F1 Score@{k}: {f1_score:.4f}\")\n",
        "\n",
        "        return {'Precision': avg_precision, 'Recall': avg_recall, 'F1': f1_score}\n",
        "\n",
        "\n",
        "\n",
        "evaluator = RecommenderEvaluator(orders_df)\n",
        "\n",
        "# 1. Evaluate prediction accuracy\n",
        "rating_metrics = evaluator.evaluate_collaborative_filter(model_class=SVD)\n",
        "\n",
        "# 2. Evaluate recommendation ranking quality (Top-5 items)\n",
        "ranking_metrics = evaluator.evaluate_top_n(model_class=SVD, k=5, threshold=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRKvtOLSMLmx",
        "outputId": "ca5e775a-90cd-486e-b42b-710e837b93ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating Collaborative Filtering Model (SVD) ---\n",
            "  Root Mean Square Error (RMSE): 1.4851\n",
            "  Mean Absolute Error (MAE): 1.2670\n",
            "\n",
            "--- Evaluating Top-5 Recommendation Quality (Precision/Recall) ---\n",
            "Using relevance threshold: 4 (e.g., ratings >= 4 are 'relevant')\n",
            "  Average Precision@5: 0.3715\n",
            "  Average Recall@5: 0.9917\n",
            "  F1 Score@5: 0.5406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A/B Test Statistical Analysis Code"
      ],
      "metadata": {
        "id": "iKTA_daETk_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "def analyze_ab_test_results(group_a_users, group_a_conversions, group_b_users, group_b_conversions, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a two-proportion Z-test to determine if the difference\n",
        "    in conversion rates between Group A and Group B is statistically significant.\n",
        "\n",
        "    Args:\n",
        "        group_a_users (int): Total number of users in the control group (A).\n",
        "        group_a_conversions (int): Total number of conversions (orders) in group A.\n",
        "        group_b_users (int): Total number of users in the treatment group (B).\n",
        "        group_b_conversions (int): Total number of conversions (orders) in group B.\n",
        "        alpha (float): The significance level (default is 0.05).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Define the input data for the Z-test\n",
        "    count = np.array([group_a_conversions, group_b_conversions])\n",
        "    nobs = np.array([group_a_users, group_b_users])\n",
        "\n",
        "    # 2. Perform the two-proportion Z-test\n",
        "    # The proportions_ztest function returns the z-statistic and the two-sided p-value\n",
        "    z_stat, p_value = proportions_ztest(count, nobs, alternative='two-sided')\n",
        "\n",
        "    # 3. Calculate metrics for reporting\n",
        "    cr_a = group_a_conversions / group_a_users\n",
        "    cr_b = group_b_conversions / group_b_users\n",
        "\n",
        "    # 4. Determine significance\n",
        "    is_significant = p_value < alpha\n",
        "\n",
        "    # 5. Output Results\n",
        "    print(\"--- A/B Test Analysis: Hybrid Recommender vs. Legacy ---\")\n",
        "    print(f\"Significance Level (alpha): {alpha}\")\n",
        "    print(\"\\n## ðŸ“Š Observed Metrics\")\n",
        "    print(\"-\" * 35)\n",
        "    print(f\"Group A (Legacy) CR: {cr_a:.4f} ({group_a_conversions} / {group_a_users})\")\n",
        "    print(f\"Group B (Hybrid) CR: {cr_b:.4f} ({group_b_conversions} / {group_b_users})\")\n",
        "    print(f\"Observed Lift (B vs A): {((cr_b - cr_a) / cr_a) * 100:.2f}%\")\n",
        "    print(\"-\" * 35)\n",
        "\n",
        "    print(\"\\n## ðŸ”¬ Statistical Test Results\")\n",
        "    print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "    print(f\"P-value: {p_value:.6f}\")\n",
        "\n",
        "    print(\"\\n## âœ… Conclusion\")\n",
        "    if is_significant and cr_b > cr_a:\n",
        "        print(f\"Result: SUCCESS! (P-value < {alpha})\")\n",
        "        print(\"Action: **Reject the Null Hypothesis.** The Hybrid System (B) drives a statistically significant higher conversion rate. Proceed with full rollout.\")\n",
        "    elif is_significant and cr_a > cr_b:\n",
        "        print(f\"Result: FAILURE! (P-value < {alpha})\")\n",
        "        print(\"Action: **Reject the Null Hypothesis.** The Hybrid System (B) is significantly worse. Stop the test and investigate the cause.\")\n",
        "    else:\n",
        "        print(f\"Result: INCONCLUSIVE (P-value >= {alpha})\")\n",
        "        print(\"Action: **Fail to Reject the Null Hypothesis.** The observed difference is likely due to chance. Iterate on the model or run the test longer.\")\n",
        "\n",
        "\n",
        "# --- Hypothetical Data from Previous Example ---\n",
        "# Assume 100,000 users were shown the recommendations in each group\n",
        "N_users = 100000\n",
        "\n",
        "# Group A: Legacy System (Control)\n",
        "A_conversions = 18000 # 18.0% CR\n",
        "\n",
        "# Group B: Hybrid System (Treatment)\n",
        "B_conversions = 21500 # 21.5% CR\n",
        "\n",
        "# Run the analysis\n",
        "analyze_ab_test_results(\n",
        "    group_a_users=N_users,\n",
        "    group_a_conversions=A_conversions,\n",
        "    group_b_users=N_users,\n",
        "    group_b_conversions=B_conversions\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6iLg33hT4Pg",
        "outputId": "b94c8927-6d8a-4668-c86a-10c12fa0b6c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- A/B Test Analysis: Hybrid Recommender vs. Legacy ---\n",
            "Significance Level (alpha): 0.05\n",
            "\n",
            "## ðŸ“Š Observed Metrics\n",
            "-----------------------------------\n",
            "Group A (Legacy) CR: 0.1800 (18000 / 100000)\n",
            "Group B (Hybrid) CR: 0.2150 (21500 / 100000)\n",
            "Observed Lift (B vs A): 19.44%\n",
            "-----------------------------------\n",
            "\n",
            "## ðŸ”¬ Statistical Test Results\n",
            "Z-statistic: -19.6583\n",
            "P-value: 0.000000\n",
            "\n",
            "## âœ… Conclusion\n",
            "Result: SUCCESS! (P-value < 0.05)\n",
            "Action: **Reject the Null Hypothesis.** The Hybrid System (B) drives a statistically significant higher conversion rate. Proceed with full rollout.\n"
          ]
        }
      ]
    }
  ]
}